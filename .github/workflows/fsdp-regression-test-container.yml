name: FSDP Regression Test (container)

# TODO: Additional configuration options as inputs (egs. number of nodes (auto change num GPUs and EFA variables accordingly), add support for g* instances etc)

on: 
  pull_request:
    paths:
      - '3.test_cases/pytorch/FSDP/**'

  workflow_dispatch:
    inputs:
      model_config:
        description: 'Model configuration to use (egs. llama2_7b). Make sure this file is defined in /awsome-distributed-training/3.test_cases/pytorch/FSDP/models/<model_config>.txt'
        required: true
        default: 'llama2_7b'
        type: string
      cluster:
        description: 'Cluster to run the test on (egs. p5)'
        required: true
        default: 'p5'
        type: choice
        options:
          - p4de
          - p5
          - p5en
          - p6
jobs:
  regression:
    runs-on: [self-hosted, "${{ github.event.inputs.cluster || 'p5' }}"]
    timeout-minutes: 360  # 6 hours for the full Llama 2 test
    env:
      USER_NAME: github
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          path: ${{ github.event.run_id }}

      - name: Set env vars
        run: |
          HOME_DIR="/home/${{ env.USER_NAME }}"
          BUILD_ID="${{ github.run_id }}"
          TEST_ROOT="${HOME_DIR}/regression-test-${BUILD_ID}"
          TEST_DIR="${TEST_ROOT}/test"
          LOG_DIR="${TEST_ROOT}/regression-logs"
          CHECKPOINT_DIR="${TEST_ROOT}/regression-checkpoints"
          CONTAINER_DIR="${TEST_ROOT}/container"

          MODEL_CONFIG="${{ github.event.inputs.model_config || 'llama2_7b' }}"

          echo "HOME_DIR=$HOME_DIR" >> $GITHUB_ENV
          echo "TEST_ROOT=$TEST_ROOT" >> $GITHUB_ENV
          echo "TEST_DIR=$TEST_DIR" >> $GITHUB_ENV
          echo "LOG_DIR=$LOG_DIR" >> $GITHUB_ENV
          echo "CHECKPOINT_DIR=$CHECKPOINT_DIR" >> $GITHUB_ENV
          echo "CONTAINER_DIR=$CONTAINER_DIR" >> $GITHUB_ENV
          echo "MODEL_CONFIG=$MODEL_CONFIG" >> $GITHUB_ENV
          echo "Env vars set successfully!"

      - name: Create test directory
        run: |
          FSDP_DIR=$(pwd)/3.test_cases/pytorch/FSDP
          cd $FSDP_DIR
          mkdir -p ${{ env.TEST_DIR }}/slurm ${{ env.TEST_DIR }}/src/model_utils ${{ env.TEST_DIR }}/models ${{ env.CONTAINER_DIR }}
          mkdir -p ${{ env.LOG_DIR }} ${{ env.CHECKPOINT_DIR }}
          chmod 755 ${{ env.LOG_DIR }} ${{ env.CHECKPOINT_DIR }} ${{ env.CONTAINER_DIR }}
          cp -r src/model_utils/* ${{ env.TEST_DIR }}/src/model_utils/
          cp src/train.py src/requirements.txt ${{ env.TEST_DIR }}/src/
          cp -r models/* ${{ env.TEST_DIR }}/models/
          cp Dockerfile ${{ env.TEST_DIR }}/
          cp -r ../../../micro-benchmarks/ ${{ env.TEST_DIR }}
          echo "Test directory created successfully!"
      
      - name: Build container [on head node]
        working-directory: ${{ env.TEST_DIR }}
        run: |
          echo "Building FSDP image"
          docker build -t fsdp:pytorch .
          echo "FSDP Image built!"

      - name: Convert built container to squash file [on head node]
        working-directory: ${{ env.TEST_DIR }}
        run: |
          echo "Converting container to squash file..."
          enroot import -o ${{ env.CONTAINER_DIR }}/fsdp.sqsh dockerd://fsdp:pytorch
          echo "Container converted to squash file successfully!"

      - name: Create regression test script
        working-directory: ${{ env.TEST_DIR }}
        run: |
          cat > $TEST_DIR/slurm/regression_test.sbatch << EOF
          #!/bin/bash

          #SBATCH --nodes=4
          #SBATCH --job-name=fsdp_regression_test
          #SBATCH --output=${{ env.LOG_DIR }}/regression_test_%j.out
          #SBATCH --error=${{ env.LOG_DIR }}/regression_test_%j.err
          #SBATCH --exclusive

          set -ex;

          GPUS_PER_NODE=8

          WORKING_DIR=${{ env.TEST_DIR }}
          MODEL_CONFIG=${{ env.MODEL_CONFIG }}

          ###############################
          ###### Container Variable #####
          ###############################
          export CONTAINER_IMAGE=${{ env.CONTAINER_DIR }}/fsdp.sqsh
          export DATA_PATH=/fsx
          export FSX_MOUNT=\$WORKING_DIR:\$DATA_PATH

          export FI_LOG_LEVEL=warn
          export NCCL_DEBUG=info
          export FI_PROVIDER=efa
          export FI_EFA_USE_HUGE_PAGE=0
          export FI_EFA_SET_CUDA_SYNC_MEMOPS=0
          export LD_PRELOAD=/usr/local/cuda-12.8/lib/libnccl.so
          export NCCL_SOCKET_IFNAME=^docker,lo,veth,eth
          export HF_HUB_ETAG_TIMEOUT=60

          # Debug information
          echo "Current directory: \$(pwd)"
          echo "Working directory: \$WORKING_DIR"
          ls -la
          echo "Python version: \$(python3 --version)"
          
          ########################
          ####### Container ######
          ########################
          if [ ! -z \$CONTAINER_IMAGE ];
          then
            echo "CONTAINER_IMAGE found"
            declare -a ARGS=(
                --container-image \$CONTAINER_IMAGE
                --container-mounts \$FSX_MOUNT,${{ env.CHECKPOINT_DIR }}:/checkpoints
            )
          fi
          echo "ARGS: \${ARGS[@]}"

          declare -a TORCHRUN_ARGS=(
              --nproc_per_node=\$GPUS_PER_NODE
              --nnodes=\$SLURM_JOB_NUM_NODES
              --rdzv_id=\$SLURM_JOB_ID
              --rdzv_backend=c10d
              --rdzv_endpoint=\$(hostname)
          )
          
          export TORCHRUN=torchrun
          export TRAIN_SCRIPT=/fsx/src/train.py

          CONFIG_FILE=\$WORKING_DIR/models/\${MODEL_CONFIG}.txt
          if [ ! -f \$CONFIG_FILE ]; then
            echo "Config file \$CONFIG_FILE does not exist!"
            exit 1
          fi

          TRAINING_ARGS=()
          while IFS= read -r line || [ -n "\$line" ]; do
            [[ -z "\$line" || "\$line" =~ ^[[:space:]]*# ]] && continue

            # Strip comments!!!
            cleaned_line="\${line%%#*}"
            cleaned_line="\$(echo "\$cleaned_line" | sed 's/[[:space:]]*$//')"

            [[ -z "\$cleaned_line" ]] && continue

            if [[ "\$cleaned_line" == *"--checkpoint_dir="* ]]; then
              TRAINING_ARGS+=("--checkpoint_dir=/checkpoints")
            else
              TRAINING_ARGS+=("\$cleaned_line")
            fi

          done < "\$CONFIG_FILE"

          echo "Training arguments:"
          printf "  %s\n" "\${TRAINING_ARGS[@]}"

          echo "Running training with torchrun"
          srun -l \${ARGS[@]} \${TORCHRUN} "\${TORCHRUN_ARGS[@]}" \${TRAIN_SCRIPT} "\${TRAINING_ARGS[@]}"
          exit \$?
          EOF
          chmod +x $TEST_DIR/slurm/regression_test.sbatch


      - name: Run regression test
        id: run_test
        working-directory: ${{ env.TEST_DIR }}
        run: |
          echo "Submitting Slurm job..."
          TEST_DIR=${{ env.TEST_DIR }} sbatch --wait slurm/regression_test.sbatch
          exit_code=$?
          echo "exit_code=$exit_code" >> $GITHUB_OUTPUT
          echo "Slurm job completed with exit code: $exit_code"

      - name: List logs
        if: always()
        run: |
          echo "Contents of logs directory:"
          ls -la ${{ env.LOG_DIR }}/ || echo "No logs directory found"
          for log in ${{ env.LOG_DIR }}/regression_test_*.out; do
            if [ -f "$log" ]; then
              echo "=== Job Output ($log) ==="
              cat "$log"
            fi
          done
          for log in ${{ env.LOG_DIR }}/regression_test_*.err; do
            if [ -f "$log" ]; then
              echo "=== Job Error ($log) ==="
              cat "$log"
            fi
          done

      - name: Cleanup
        if: success()
        run: |
          echo "Cleaning up..."
          rm -rf ${{ env.TEST_ROOT }}
          echo "Test directory cleaned up successfully!"

    