This test case demonstrates distributed training of Picotron, a fast and efficient transformer model optimized for autoregressive text generation. Picotron is designed for training speed, scalability, and memory efficiency.


## Build Environment

You need to set up Python 3.10 virutal environement.




```bash
docker build -f picotron.Dockerfile .
```


## Referenecs
* https://github.com/huggingface/picotron