apiVersion: "kubeflow.org/v1"
kind: PyTorchJob
metadata:
  name: stable-diffusion
spec:
  elasticPolicy:
    rdzvBackend: etcd
    rdzvHost: etcd
    rdzvPort: 2379
    minReplicas: 1
    maxReplicas: 96
    maxRestarts: 100
  pytorchReplicaSpecs:
    Worker:
      replicas: ${NUM_NODES}
      restartPolicy: OnFailure
      template:
        metadata:
          labels:
            app: stable-diffusion
        spec:
          volumes:
            - name: shmem
              hostPath:
                path: /dev/shm
          containers:
            - name: pytorch
              image: ${REGISTRY}${DOCKER_IMAGE_NAME}:{TAG}
              imagePullPolicy: Always
              resources:
                requests:
                  nvidia.com/gpu: 8
                  vpc.amazonaws.com/efa: 32
                limits:
                  nvidia.com/gpu:
                  vpc.amazonaws.com/efa: 32
              env:
              - name: LOGLEVEL
                value: "DEBUG"
              - name: NCCL_DEBUG
                value: "INFO"
              - name: NCCL_ASYNC_ERROR_HANDLING
                value: "1"
              - name: WANDB_MODE
                value: "offline"
              command:
                - bash
                - -c
                - "composer -n ${NUM_GPUS_PER_NODE} --world_size ${WORLD_SIZE} --node_rank $(hostname | cut -d- -f4-) --master_addr stable-diffusion-worker-0 --master_port ${MASTER_PORT} benchmark.py --use_ema --use_synth_data --device_train_microbatch_size 4"
              volumeMounts:
                - name: shmem
                  mountPath: /dev/shm
