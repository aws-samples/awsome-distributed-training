apiVersion: "v1"
kind: Pod
metadata:
  name: tokenize-data
  namespace: kubeflow
spec:

      volumes:
        - name: shmem
          hostPath:
            path: /dev/shm
        - name: persistent-storage
          persistentVolumeClaim:
            claimName: ${FSX_CLAIM}
        - name: local
          hostPath:
            path: /dev
        - name: hyperpod
          hostPath:
            path: /var/log/aws/clusters
      containers:
          - name: trn-container
            image: '${IMAGE_URI}'
            command:
                - python 
                - tokenize_data.py
                - --model_name=${HF_MODEL_NAME}
                - --hf_access_token=${HF_ACCESS_TOKEN}
                - --save_path=${TOKENIZED_DATA_PATH}
                - --dataset_name=${DATASET_NAME}
                - --dataset_config_name=${dATASET_CONFIG_NAME}
            volumeMounts:
              - name: shmem
                mountPath: /dev/shm
              - name: persistent-storage
                mountPath: /fsx
              - name: hyperpod
                mountPath: /var/log/aws/clusters
            resources:
              requests:
                aws.amazon.com/neuron: ${NEURON_PER_NODE}
                vpc.amazonaws.com/efa: ${EFA_PER_NODE}
              limits:
                aws.amazon.com/neuron: ${NEURON_PER_NODE}
                vpc.amazonaws.com/efa: ${EFA_PER_NODE}
      
      restartPolicy: Never
