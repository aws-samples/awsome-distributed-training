--max_context_width=4096
--num_key_value_heads=32
--intermediate_size=11008
--hidden_width=4096
--num_layers=32
--num_heads=32
--model_type=llama_v2
--tokenizer="hf-internal-testing/llama-tokenizer"
--checkpoint_freq=5000
--validation_freq=500
--max_steps=5000
--checkpoint_dir=./checkpoints
--dataset='allenai/c4'
--dataset_config_name='en'
--resume_from_checkpoint=./checkpoints
--train_batch_size=1
--val_batch_size=1
--sharding_strategy="full" # https://pytorch.org/docs/stable/fsdp.html
--offload_activations=1