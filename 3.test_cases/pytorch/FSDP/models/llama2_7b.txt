--max_context_width=4096
--num_key_value_heads=32
--intermediate_size=11008
--hidden_width=4096
--num_layers=32
--num_heads=32
--model_type=llama_v2
--tokenizer=hf-internal-testing/llama-tokenizer
--checkpoint_freq=50
--validation_freq=100
--max_steps=100
--checkpoint_dir=./checkpoints
--dataset=allenai/c4
--dataset_config_name=en
--resume_from_checkpoint=./checkpoints
--train_batch_size=1
--val_batch_size=1
--sharding_strategy=full # https://pytorch.org/docs/stable/fsdp.html
--offload_activations=1