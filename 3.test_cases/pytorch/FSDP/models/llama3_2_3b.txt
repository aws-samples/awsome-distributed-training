--max_context_width=8192
--num_key_value_heads=2
--intermediate_size=8192
--hidden_width=3072
--num_layers=28
--num_heads=24
--model_type=llama_v3
--tokenizer=hf-internal-testing/llama-tokenizer
--checkpoint_freq=50
--validation_freq=100
--max_steps=100
--checkpoint_dir=./checkpoints
--dataset=allenai/c4
--dataset_config_name=en
--resume_from_checkpoint=./checkpoints
--train_batch_size=1
--val_batch_size=1
--sharding_strategy=full # https://pytorch.org/docs/stable/fsdp.html
--offload_activations=1